:PROPERTIES:
:ID:       a5ad6850-d20d-42e4-908d-98cc9beb8695
:END:
#+title: ift2245-threads
#+STARTUP: latexpreview inlineimages
#+date: [2022-01-28 Fri 23:48]

Une introduction aux [[id:dfef35ec-f393-4d26-abc9-8ea1711c3511][threads]]

* Avantages

1. Accéleration grâce à la *parallélisation*

  [[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220128_235110_LEY2XZ.png]]

   - *Parallélisme des données* - Distribue des sous-ensembles des mêmes données sur plusieurs coeurs, chaque coeur fait la même opération

2. Augmentation des performances grâce à la *spécialisation*

   - Contrôler l'efficacité par priorisation aux différentes tâches
   - Si on peut représenter l'état du processus avec une grandeur à peu près comme le *cache* dans le processeur - Alors on peut exécuter la tâche au complet tout en utilisant la mémoire allouée au *cache* du CPU
     - Donc si on distribue bien les tâches aux différents CPU et que la tâche peut se faire au complet au travers de la mémoire cache du CPU, les données utiles vont être très proches qui impliquent que chaque thread pourrait théoriquement terminer plus rapidement selon la distribution
     - Le terme *hot-cache* désigne cet effet - Moins de temps perdu pour aller à la *mémoire centrale* puisque toutes les données utiles sont dans la *cache* du CPU

     [[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220128_235422_rFyORO.png]]

   - *Parallélisme des tâches* - Distribution des threads à travers les coeurs, chaque thread effectuant une opération unique

3. La communication *inter-thread* est plus simple

   - Les différents threads s'exécutent dans le même espace d'adressage - Rien à faire pour organiser un système de communication avec la mémoire partagée car la mémoire est déjà partagée entre les threads
   - Pas besoin de tuyaux ou de sockets
     
     [[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_000809_xm42pW.png]]

4. L'utilisation de la mémoire est plus efficace

   - Si on avait 4 processus, chaque processus à son propre espace d'adressage (EA) et son contexte d'exécution (CE)
   - Dans le cas de multi-thread, juste un EA avec 4 CE
     - Dans la création de processus et /context switch/ - Moins d'effort à bouger les données dans le EA

       [[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_001316_3eAnWa.png]]

       - Certaines des données propres à un processus n'ont pas besoin d'être copier car les threads font parties du même processus et dans le même espace d'adressage

* Loi d'Amdahl

Identifie les gains de performances résultant de l'ajout de coeurs supplémentaires à une application qui comporte des composants série et parallèle

$\mathrm{speedup} \leq \frac 1 {S + \frac {(1 - S)} N}$

- $S$ - Portion dexécution séquentielle
- $N$ - Nombres de processeurs

Ex.: Si l'appliction est 75% parallèle / 25% séquentielle
- De 1 à 2 cores entraîne une accélération de $1.6 \times$
- De 1 à 4 cores entraîne une accélération de $2.29 \times$
- Lorsque $N$ tend vers l'infini, l'accélération tend vers $1 / S$

La partie séquentielle d'une application a un effet inversement proportionnel (disproportionné) sur les performances obtenues en ajoutant plus de cores

* Programmation Multicore

Systèmes *multicore* ou *multiprocesseurs* mets la responsabilité sur les programmeurs d'adapter leurs applications pour supporter le multithreading
- Tels que l'ordre d'exécution, la synchronisation, les accès mémoires, etc... qui ne sont pas gérés dans l'espace d'adressage puisqu'il est partagé

Les défis comprennent:
- *Diviser les activités* en tâches distinctes et simultanées
- *Balance* - Doit essayer d'obtenir un travail équivalent pour les tâches
- *Division des données* - Pour éviter les collisions de données
- *Dépendance des données* - Synchronisation pour la dépendance des données
- *Test et déboggage* - Plus complexe que systèmes simple threaded

* Threads noyau

On doit établir une relation entre les threads utilisateur et les threads du noyau
- Exemple - Comment gérer les appels systèmes fait par les threads, faut-il bloquer le processus...
- Différents SE traitent différemment la relation entre les threads utilisitauer et noyau

[[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_003647_kofJnF.png]]

Trois modèles:
- *un à un*
- *plusieurs à un*
- *plusieurs à plusieurs*

** Plusieurs à un

De nombreux *threads de niveau utilisateur* associés à un *thread de noyau unique*

- Avantages:
  - L'exécution de l'application est indépendante du système d’exploitation
    - Du niveau de l'ordonnancement, l'application peut coordonner la relation entre ses threads, juste une thread noyau
    
- Désavantages:
  - Le système d'exploitation n'a aucune information sur les besoins réels de l’application
  - Un blocage de thread (par exemple, un appel système) provoque le blocage de tous
    
[[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_004649_X0Yw7E.png]]

** Un à un

Chaque *thread de niveau utilisateur* correspond a un *thread du noyau*
- La création d'un thread de niveau utilisateur crée un thread de noyau

- Avantages:
  - Plus d'accès simultané que modèle *plusieurs à un*
  - L'application bénéficie de l'implémentation OS du *multi-threading* en termes de synchronisation, de blocage, etc.

- Désavantages:
  - Le nombre de *threads par processus* est parfois limité en raison du *temps de création* des threads du noyau
    - Création de thread utilisateur engendrerais une création de thread par noyau
  - Il y a moins de flexibilité dans la façon dont les applications sont planifiées car elles sont *liées plus étroitement* au système d'exploitation

[[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_003903_quK0Ga.png]]

** Plusieurs à plusieurs

Permet à de nombreux threads de niveau utilisateur d'être mappés vers de nombreux threads du noyau (plus petits ou égaux)

- Avantages:
  - Permet au système d'exploitation de créer un nombre suﬃsant de threads du noyau, en fonction de sa configuration matérielle
  - Donne la possibilité à l'utilisateur de créer autant de threads utilisateur que souhaité

- Désavantages:
  - Plus compliqué
  - Nécessite une coordination entre le système d'exploitation et les gestionnaires de threads au niveau de l’utilisateur

[[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_005129_hmmLZV.png]]

** Modèle à deux niveaux

Similaire à *plusieurs à plusieurs*, sauf qu'il permet à un thread utilisateur d'être lié à un thread du noyau

[[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_005401_DoJ8mb.png]]

* Scope

Le /scope/ est la portée d'un objet quelconque

Soit le situation suivante:

[[/home/phil-gab99/Documents/Notes/IFT-2245/20220128234819-threads.org_20220129_005557_uxTC1D.png]]

- Supposons que le processus ~P1~ a beaucoup plus de threads que ~P2~
  - Faut-il gérer toutes les threads à un *niveau système* en partageant toutes les ressources à un *niveau système*
  - Faut-il plutôt partager les ressources chaque processus par lui-même pour gérer les ressources qui lui sont allouées

Différents *scopes* que l'on peut introduire
- *Scope niveau processus* - Plus petite portée
  - Les threads sont gérés (et sont en compétition pour les ressources) dans un seul processus
    
- *Scope niveau système* - Plus grande portée (sees the bigger picture)
  - Les threads sont gérés au niveau du système d'exploitation par des gestionnaires de threads et sont en concurrence

* Signaux - SIGTERM

Les *signaux* sont utilisés dans les systèmes UNIX pour notifier un processus qu'un *événement particulier* s'est produit
- Où faut-il fournir un signal pour une situation multi-threaded? (dépend du type de signal):
  1. Livrer le signal au *thread auquel le signal s'applique* (par exemple, synchrone)
  2. Livrer le signal à *chaque thread dans le processus* (par exemple, ctrl-c interruption)
  3. Fournit le signal à *certains threads du processus* (par exemple, l'élément de base de données a été récupéré)
  4. Aﬀecter un *thread spécifique* pour recevoir tous les signaux du processus

* Stockage "Thread-Local" (TLS)

Les threads d'un processus partagent généralement les données du processus
- *Stockage Thread-local* (TLS) permet à chaque thread d'avoir sa *propre copie protégée des données*
- Utile lorsqu'on n'a aucun contrôle sur le processus de création de thread (c'est-à-dire lorsqu'on utilise un *pool de threads*)

- Diﬀérent des variables locales
  - Variables locales $\Rightarrow$ Visibles uniquement lors d'une invocation de fonction unique
  - TLS $\Rightarrow$ Visible à travers les invocations de fonctions

- Similaire aux *données statiques* (ex.: en Java)
  - TLS est unique à chaque thread
